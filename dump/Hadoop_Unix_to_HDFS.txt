#!/bin/bash

sourcefiledir=/data/staging/g00103/ge_power/iqp/FlatFiles
hdfsexternaldir=/tmp/iqp/externalfiles
archivedir=/data/staging/g00103/ge_power/iqp/FlatFiles_archive
groupmap=/data/staging/g00103/ge_power/iqp/ShellScripts/groupmap.psv
error=0

rm -f /data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile*

> /data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile`date +%Y-%m-%d`
> /data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile_error_ind`date +%Y-%m-%d`

chmod 777 /data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile`date +%Y-%m-%d`
chmod 777 /data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile_error_ind`date +%Y-%m-%d`

log=/data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile`date +%Y-%m-%d`
error_log_ind=/data/staging/g00103/ge_power/iqp/ShellScripts/hdfs_logfile_error_ind`date +%Y-%m-%d`

#touch $error_log_ind


echo "Start of HDFS Script"
echo "Start of HDFS Script" >> $log
echo "--------------------------"
echo "--------------------------" >> $log

#defining date variable to fetch the current date files



  #Reading all files from mapping table
	    IFS="|"
	    while read f1 f2
	    do
	    inputfile=$inputfile" "$f2
	    done < $groupmap
	              				
            echo $inputfile
            echo $inputfile >> $log
            echo "--------------------------"
	    echo "--------------------------" >> $log
   	      
   	    
	    #Deleting exteranl directory and re creating it 
	    hdfs dfs -rm -r $hdfsexternaldir
	    
	    if [[ $? != 0 ]];
	    then
	       echo "directory removal process failed" 
	       echo "directory removal process failed" >> $log
	       exit 9999
	       
	    fi
	    
	    hdfs dfs -mkdir $hdfsexternaldir
	    hdfs dfs -chmod 777 $hdfsexternaldir/
	    
	    check=`hdfs dfs -ls $hdfsexternaldir | wc -l`
	    
		    if [[ ${check} == ""  ]] ;
			then 
			echo "directory not created existing" 
			echo "directory not created existing" >> $log
			exit 9999
		     fi 
	


#Move file for a given table to HDFS directory 
IFS=" "

for file in $inputfile

do
       file=$(echo $file | xargs) 
       if [[  $file == "ARCH_sales"  ]];
          then file_new="Spain_sales"
		
	   elif [[ $file == "ARCH_orders"  ]];
          then file_new="Spain_orders"
	   
	   elif [[ $file == "ARCH_backlog"  ]];
          then file_new="Spain_backlog"
		  
       elif [[ $(echo $file| cut -c 1-4) == "ARCH"  ]];
          then file_new=$( echo $file| cut -c 6-)
		  
	   elif [[ $(echo $file| cut -c 1-10) == "SAP_Orders"  ]];
          then 	file_new="SAP_Orders"
		  
       else 
          file_new=$file 
       fi
	   file_new1=$(echo "$file_new" | awk '{print tolower($0)}')
	#Creating directoty
	hdfs dfs -mkdir $hdfsexternaldir/iqp_${file_new1}__x
	#Giving permission
	hdfs dfs -chmod 777 $hdfsexternaldir/iqp_${file_new1}__x
	#copy files to hdfs directoty 
	hdfs dfs -copyFromLocal -f ${sourcefiledir}/${file}*  ${hdfsexternaldir}/iqp_${file_new1}__x
	
	
		if [[ $? != 0 ]];
		then
		echo "HDFS copy failed for ${file}" 
		echo "HDFS copy failed for ${file}" >> $log
		error=`expr ${error} + 1`
		
		else 
		
		echo "file copy completed" 
		echo "file copy completed" >> $log
	 	fi
	
	
	#Archive files 
	
	mv ${sourcefiledir}/${file}* ${archivedir}/
	echo "File ${file}__x archived "  >> $log
	
	echo "--------------------------"
        echo "--------------------------" >> $log
done


error=$(echo $error | xargs) 



if [[ ${error} -gt 0  ]] ;
then
echo "End of HDFS Script|${error} " >> $error_log_ind
echo "" >> $error_log_ind
fi

echo "End of HDFS Script : files with error ${error} "
echo "End of HDFS Script : files with error ${error} " >> $log
